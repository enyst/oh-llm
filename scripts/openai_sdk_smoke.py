from __future__ import annotations

import argparse
import json
import os
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from oh_llm.profiles import ProfileRecord, upsert_profile


def _repo_root() -> Path:
    return Path(__file__).resolve().parents[1]


def _utc_slug() -> str:
    return datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S")


def _run_oh_llm_json(
    *,
    args: list[str],
    cwd: Path,
    env: dict[str, str],
) -> tuple[int, dict[str, Any]]:
    proc = subprocess.run(
        [
            sys.executable,
            "-c",
            "from oh_llm.cli import main; main()",
            *args,
        ],
        cwd=str(cwd),
        env=env,
        capture_output=True,
        text=True,
        check=False,
    )

    stdout = (proc.stdout or "").strip()
    if not stdout:
        return proc.returncode, {"ok": False, "error": proc.stderr.strip() or "No output."}

    last_line = stdout.splitlines()[-1].strip()
    try:
        payload = json.loads(last_line)
    except json.JSONDecodeError:
        payload = {"ok": False, "error": "Failed to parse JSON output.", "stdout": stdout}

    return proc.returncode, payload


def _read_json_file(path: Path) -> dict[str, Any]:
    return json.loads(path.read_text(encoding="utf-8"))


def _summarize_human(*, profile: ProfileRecord, run_dir: Path, run: dict[str, Any]) -> str:
    stages = run.get("stages") if isinstance(run.get("stages"), dict) else {}
    stage_a = stages.get("A") if isinstance(stages.get("A"), dict) else {}
    stage_b = stages.get("B") if isinstance(stages.get("B"), dict) else {}
    a_status = stage_a.get("status", "unknown")
    b_status = stage_b.get("status", "not_run")

    sdk = run.get("agent_sdk") if isinstance(run.get("agent_sdk"), dict) else {}
    sdk_sha = sdk.get("git_sha")
    sdk_path = sdk.get("path")

    failure = run.get("failure") if isinstance(run.get("failure"), dict) else {}
    classification = failure.get("classification")

    lines = [
        f"Profile: {profile.profile_id}",
        f"- model: {profile.model}",
        f"- base_url: {profile.base_url or '(default)'}",
        f"- api_key_env: {profile.api_key_env}",
        "",
        f"Run dir: {run_dir}",
        f"- stage A: {a_status}",
        f"- stage B: {b_status}",
    ]
    if classification:
        lines.append(f"- failure classification: {classification}")
    if sdk_path or sdk_sha:
        lines.append("")
        lines.append("agent-sdk:")
        if sdk_path:
            lines.append(f"- path: {sdk_path}")
        if sdk_sha:
            lines.append(f"- git_sha: {sdk_sha}")
    return "\n".join(lines).strip() + "\n"


def main() -> None:
    parser = argparse.ArgumentParser(
        description=(
            "Manual OpenAI-compatible/agent-sdk compatibility smoke for oh-llm.\n\n"
            "Creates (or reuses) an SDK on-disk profile and runs `oh-llm run` "
            "for Stage A, optionally Stage B."
        )
    )
    parser.add_argument("--model", help="LiteLLM model string (e.g. openai/gpt-4o-mini).")
    parser.add_argument(
        "--base-url",
        default=None,
        help="Optional OpenAI-compatible base URL (provider-specific).",
    )
    parser.add_argument(
        "--api-key-env",
        dest="api_key_env",
        help="Name of env var holding the API key (value is never stored).",
    )
    parser.add_argument(
        "--profile-id",
        default=None,
        help="Optional profile id to create/update (default: autogenerated).",
    )
    parser.add_argument(
        "--overwrite-profile",
        action="store_true",
        help="Overwrite existing profile + metadata if present.",
    )
    parser.add_argument(
        "--runs-dir",
        default=None,
        help="Override runs directory (default: $OH_LLM_RUNS_DIR or ~/.oh-llm/runs).",
    )
    parser.add_argument(
        "--agent-sdk-path",
        default=None,
        help=(
            "Path to an agent-sdk checkout/worktree to test against. "
            "Sets $OH_LLM_AGENT_SDK_PATH for the invoked run."
        ),
    )
    parser.add_argument(
        "--stage-b",
        action="store_true",
        help="Also run Stage B (tool calling) and require TOOL_OK.",
    )
    parser.add_argument(
        "--stage-b-terminal-type",
        default="subprocess",
        help="Stage B terminal backend (subprocess or tmux).",
    )
    parser.add_argument(
        "--stage-b-max-iterations",
        type=int,
        default=50,
        help="Max iterations for Stage B.",
    )
    parser.add_argument(
        "--mock",
        action="store_true",
        help="Offline mode: no network or API keys required (creates a dummy profile).",
    )
    parser.add_argument(
        "--mock-stage-b-mode",
        default="native",
        help="Mock Stage B mode (native or compat).",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Emit machine-readable JSON output.",
    )
    args = parser.parse_args()

    mock_enabled = bool(args.mock) or bool(os.environ.get("OH_LLM_MOCK"))
    model = (args.model or "").strip()
    api_key_env = (args.api_key_env or "").strip()

    if mock_enabled:
        model = model or "mock-model"
        api_key_env = api_key_env or "MISSING_API_KEY"
    else:
        if not model:
            raise SystemExit("Missing required option: --model")
        if not api_key_env:
            raise SystemExit("Missing required option: --api-key-env")
        if not os.environ.get(api_key_env):
            raise SystemExit(f"API key env var not set: {api_key_env}")

    profile_id = (args.profile_id or f"smoke-{_utc_slug()}").strip()
    profile = upsert_profile(
        profile_id=profile_id,
        model=model,
        base_url=(str(args.base_url).strip() if args.base_url else None),
        api_key_env=api_key_env,
        overwrite=bool(args.overwrite_profile),
    )

    env = dict(os.environ)
    if args.agent_sdk_path:
        env["OH_LLM_AGENT_SDK_PATH"] = str(Path(str(args.agent_sdk_path)).expanduser())
    cwd = _repo_root()

    run_args = [
        "run",
        "--profile",
        profile.profile_id,
        "--json",
    ]
    if args.runs_dir:
        run_args.extend(["--runs-dir", str(args.runs_dir)])
    if mock_enabled:
        run_args.append("--mock")
        run_args.extend(["--mock-stage-b-mode", str(args.mock_stage_b_mode)])
    if args.stage_b:
        run_args.append("--stage-b")
        run_args.extend(["--stage-b-terminal-type", str(args.stage_b_terminal_type)])
        run_args.extend(["--stage-b-max-iterations", str(int(args.stage_b_max_iterations))])

    exit_code, payload = _run_oh_llm_json(args=run_args, cwd=cwd, env=env)
    run_dir_raw = payload.get("run_dir")
    run_dir = Path(str(run_dir_raw)) if run_dir_raw else None

    run_record: dict[str, Any] = {}
    if run_dir and run_dir.exists():
        run_json = run_dir / "run.json"
        if run_json.exists():
            run_record = _read_json_file(run_json)

    ok = bool(payload.get("ok") is True and exit_code == 0)
    stages = payload.get("stages") if isinstance(payload.get("stages"), dict) else {}

    if args.json:
        print(
            json.dumps(
                {
                    "ok": ok,
                    "profile_id": profile.profile_id,
                    "model": profile.model,
                    "base_url": profile.base_url,
                    "api_key_env": profile.api_key_env,
                    "run_dir": str(run_dir) if run_dir else None,
                    "stages": stages,
                    "agent_sdk": run_record.get("agent_sdk"),
                    "failure": payload.get("failure"),
                },
                ensure_ascii=False,
            )
        )
    else:
        if run_dir:
            print(_summarize_human(profile=profile, run_dir=run_dir, run=run_record or payload))
        else:
            print(f"Profile: {profile.profile_id}\n- model: {profile.model}\n", end="")
            print(json.dumps(payload, indent=2, ensure_ascii=False))

    raise SystemExit(0 if ok else (exit_code or 1))


if __name__ == "__main__":
    main()
