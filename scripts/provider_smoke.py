from __future__ import annotations

import argparse
import json
import os
import subprocess
import tempfile
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class ProviderPreset:
    name: str
    api_key_env: str
    required_env_vars: tuple[str, ...]
    docs_path: str
    base_url: str | None = None


_PRESETS: dict[str, ProviderPreset] = {
    "openai": ProviderPreset(
        name="openai",
        api_key_env="OPENAI_API_KEY",
        required_env_vars=("OPENAI_API_KEY",),
        docs_path="docs/providers/openai.md",
        base_url=None,
    ),
    "gemini": ProviderPreset(
        name="gemini",
        api_key_env="GEMINI_API_KEY",
        required_env_vars=("GEMINI_API_KEY",),
        docs_path="docs/providers/gemini.md",
        base_url=None,
    ),
    "azure_openai": ProviderPreset(
        name="azure_openai",
        api_key_env="AZURE_API_KEY",
        required_env_vars=("AZURE_API_KEY", "AZURE_API_BASE", "AZURE_API_VERSION"),
        docs_path="docs/providers/azure-openai.md",
        base_url=None,
    ),
    "openrouter": ProviderPreset(
        name="openrouter",
        api_key_env="OPENROUTER_API_KEY",
        required_env_vars=("OPENROUTER_API_KEY",),
        docs_path="docs/providers/openrouter.md",
        base_url="https://openrouter.ai/api/v1",
    ),
    "groq": ProviderPreset(
        name="groq",
        api_key_env="GROQ_API_KEY",
        required_env_vars=("GROQ_API_KEY",),
        docs_path="docs/providers/groq.md",
        base_url="https://api.groq.com/openai/v1",
    ),
}


def _repo_root() -> Path:
    return Path(__file__).resolve().parents[1]


def _utc_slug() -> str:
    return datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S")


def _require_env_vars(*, preset: ProviderPreset) -> None:
    missing = [name for name in preset.required_env_vars if not os.environ.get(name)]
    if missing:
        missing_list = ", ".join(missing)
        raise SystemExit(
            f"Missing required environment variable(s): {missing_list}\n"
            f"See `{preset.docs_path}`."
        )


def _run_json_cli(*, env: dict[str, str], args: list[str], cwd: Path) -> tuple[int, dict[str, Any]]:
    proc = subprocess.run(
        ["uv", "run", "oh-llm", *args],
        cwd=str(cwd),
        env=env,
        capture_output=True,
        text=True,
        check=False,
    )
    stdout = (proc.stdout or "").strip()
    if not stdout:
        return proc.returncode, {"ok": False, "error": proc.stderr.strip() or "No output."}
    last_line = stdout.splitlines()[-1].strip()
    try:
        payload = json.loads(last_line)
    except json.JSONDecodeError:
        payload = {"ok": False, "error": "Failed to parse JSON output.", "stdout": stdout}
    return proc.returncode, payload


def main() -> None:
    parser = argparse.ArgumentParser(
        description=(
            "Manual provider smoke harness for oh-llm.\n\n"
            "Creates an isolated profile in a temporary HOME by default, then runs Stage A "
            "and optionally Stage B via `uv run oh-llm run ...`."
        )
    )
    parser.add_argument(
        "--provider",
        required=True,
        choices=sorted(_PRESETS.keys()),
        help="Provider preset name.",
    )
    parser.add_argument(
        "--model",
        required=True,
        help="LiteLLM model string (provider-specific; see docs link printed on failure).",
    )
    parser.add_argument(
        "--base-url",
        default=None,
        help="Optional override for the OpenAI-compatible base URL.",
    )
    parser.add_argument(
        "--profile-id",
        default=None,
        help="Optional profile id to create/update (default: autogenerated).",
    )
    parser.add_argument(
        "--overwrite-profile",
        action="store_true",
        help="Overwrite existing profile + metadata if present.",
    )
    parser.add_argument(
        "--runs-dir",
        default=None,
        help="Override runs directory (default: $OH_LLM_RUNS_DIR or ~/.oh-llm/runs).",
    )
    parser.add_argument(
        "--agent-sdk-path",
        default=None,
        help=(
            "Path to an agent-sdk checkout/worktree to test against. "
            "Sets $OH_LLM_AGENT_SDK_PATH for the invoked run."
        ),
    )
    parser.add_argument(
        "--stage-b",
        action="store_true",
        help="Also run Stage B (tool calling) and require TOOL_OK.",
    )
    parser.add_argument(
        "--stage-b-terminal-type",
        default="subprocess",
        help="Stage B terminal backend (subprocess or tmux).",
    )
    parser.add_argument(
        "--stage-b-max-iterations",
        type=int,
        default=50,
        help="Max iterations for Stage B.",
    )
    parser.add_argument(
        "--mock",
        action="store_true",
        help="Offline mode: pass `--mock` through to `oh-llm run` (still requires env vars).",
    )
    parser.add_argument(
        "--home-dir",
        default=None,
        help=(
            "Directory to use as $HOME for this run (isolates ~/.openhands and ~/.oh-llm). "
            "Defaults to a new temp directory."
        ),
    )
    parser.add_argument(
        "--use-user-home",
        action="store_true",
        help="Use the real user home directory (opt out of isolation).",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Emit machine-readable JSON output.",
    )
    args = parser.parse_args()

    if args.use_user_home and args.home_dir:
        raise SystemExit("Cannot combine --use-user-home and --home-dir.")

    preset = _PRESETS[args.provider]

    if args.use_user_home:
        home_dir = Path.home()
    elif args.home_dir:
        home_dir = Path(args.home_dir).expanduser()
    else:
        home_dir = Path(tempfile.mkdtemp(prefix="oh-llm-provider-smoke-home."))
    home_dir.mkdir(parents=True, exist_ok=True)

    # Validate required env vars in the *real* environment (not the isolated home).
    _require_env_vars(preset=preset)

    # Isolate profile/runs stores by default.
    env = dict(os.environ)
    env["HOME"] = str(home_dir)
    if args.agent_sdk_path:
        env["OH_LLM_AGENT_SDK_PATH"] = str(Path(args.agent_sdk_path).expanduser())

    base_url = args.base_url
    if base_url is None:
        base_url = preset.base_url

    profile_id = args.profile_id or f"{preset.name}-{_utc_slug()}"

    cwd = _repo_root()

    # Create an isolated, non-secret profile (env var name only).
    profile_add_args = [
        "profile",
        "add",
        profile_id,
        "--model",
        args.model,
        "--api-key-env",
        preset.api_key_env,
    ]
    if base_url:
        profile_add_args.extend(["--base-url", base_url])
    if args.overwrite_profile:
        profile_add_args.append("--overwrite")
    profile_add_args.append("--json")

    add_code, add_payload = _run_json_cli(env=env, args=profile_add_args, cwd=cwd)
    if add_code != 0 or add_payload.get("ok") is not True:
        raise SystemExit(add_payload.get("error") or "Failed to create profile.")

    run_args = [
        "run",
        "--profile",
        profile_id,
        "--json",
    ]
    if args.runs_dir:
        run_args.extend(["--runs-dir", args.runs_dir])
    if args.mock:
        run_args.append("--mock")
    if args.stage_b:
        run_args.append("--stage-b")
        run_args.extend(["--stage-b-terminal-type", args.stage_b_terminal_type])
        run_args.extend(["--stage-b-max-iterations", str(args.stage_b_max_iterations)])

    run_code, run_payload = _run_json_cli(env=env, args=run_args, cwd=cwd)
    run_dir = run_payload.get("run_dir")
    ok = bool(run_code == 0 and run_payload.get("ok") is True)

    result = {
        "ok": ok,
        "provider": preset.name,
        "home_dir": str(home_dir),
        "profile_id": profile_id,
        "model": args.model,
        "base_url": base_url,
        "api_key_env": preset.api_key_env,
        "required_env_vars": list(preset.required_env_vars),
        "docs_path": preset.docs_path,
        "run_dir": run_dir,
        "stages": run_payload.get("stages"),
        "failure": run_payload.get("failure"),
    }

    if args.json:
        print(json.dumps(result, ensure_ascii=False))
    else:
        print(f"Provider: {preset.name}")
        print(f"Docs: `{preset.docs_path}`")
        print(f"HOME (isolated): {home_dir}")
        print(f"Profile: {profile_id}")
        print(f"- model: {args.model}")
        if base_url:
            print(f"- base_url: {base_url}")
        print(f"- api_key_env: {preset.api_key_env}")
        print(f"Run dir: {run_dir}\n")
        if not ok:
            failure = run_payload.get("failure")
            classification = failure.get("classification") if isinstance(failure, dict) else None
            if classification:
                print(f"Failure classification: {classification}")

    raise SystemExit(0 if ok else (run_code or 1))


if __name__ == "__main__":
    main()
